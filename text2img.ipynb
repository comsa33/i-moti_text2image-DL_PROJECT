{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b1ecd0-4051-4ca4-bb0e-d1961db1dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import time\n",
    "import imageio\n",
    "from tensorflow_docs.vis import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff0671d-b4d2-4aeb-9300-534090e76cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>emoji</th>\n",
       "      <th>unicode</th>\n",
       "      <th>name</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Google</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>JoyPixels</th>\n",
       "      <th>Samsung</th>\n",
       "      <th>Gmail</th>\n",
       "      <th>SoftBank</th>\n",
       "      <th>DoCoMo</th>\n",
       "      <th>KDDI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>üòÄ</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAPAKIFAJh3AP/z...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>üòÉ</td>\n",
       "      <td>U+1F603</td>\n",
       "      <td>grinning face with big eyes</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAKIFAF5LAP/z...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDwAPAKIAAP///wAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAIABAMxm////...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDgAPALMJAP//mf/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>üòÑ</td>\n",
       "      <td>U+1F604</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAKIGAF5LAJh3...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>üòÅ</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>beaming face with smiling eyes</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAKIGAIoAAf/v...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAIABAP+ZAP//...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDgAPALMIAJmZmf//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>üòÜ</td>\n",
       "      <td>U+1F606</td>\n",
       "      <td>grinning squinting face</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhEAAMAKIFAF5LAP/z...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAIABAMxm////...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # emoji  unicode                             name  \\\n",
       "0  1     üòÄ  U+1F600                    grinning face   \n",
       "1  2     üòÉ  U+1F603      grinning face with big eyes   \n",
       "2  3     üòÑ  U+1F604  grinning face with smiling eyes   \n",
       "3  4     üòÅ  U+1F601   beaming face with smiling eyes   \n",
       "4  5     üòÜ  U+1F606          grinning squinting face   \n",
       "\n",
       "                                               Apple  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                              Google  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                            Facebook  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                             Windows  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                             Twitter  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                           JoyPixels  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                             Samsung  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                               Gmail  \\\n",
       "0  data:image/png;base64,R0lGODlhDAAPAKIFAJh3AP/z...   \n",
       "1  data:image/png;base64,R0lGODlhDAAMAKIFAF5LAP/z...   \n",
       "2  data:image/png;base64,R0lGODlhDAAMAKIGAF5LAJh3...   \n",
       "3  data:image/png;base64,R0lGODlhDAAMAKIGAIoAAf/v...   \n",
       "4  data:image/png;base64,R0lGODlhEAAMAKIFAF5LAP/z...   \n",
       "\n",
       "                                            SoftBank  \\\n",
       "0                                                NaN   \n",
       "1  data:image/png;base64,R0lGODlhDwAPAKIAAP///wAA...   \n",
       "2  data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...   \n",
       "3  data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              DoCoMo  \\\n",
       "0                                                NaN   \n",
       "1  data:image/png;base64,R0lGODlhDAAMAIABAMxm////...   \n",
       "2                                                NaN   \n",
       "3  data:image/png;base64,R0lGODlhDAAMAIABAP+ZAP//...   \n",
       "4  data:image/png;base64,R0lGODlhDAAMAIABAMxm////...   \n",
       "\n",
       "                                                KDDI  \n",
       "0                                                NaN  \n",
       "1  data:image/png;base64,R0lGODlhDgAPALMJAP//mf/M...  \n",
       "2                                                NaN  \n",
       "3  data:image/png;base64,R0lGODlhDgAPALMIAJmZmf//...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = 'dataset/full_emoji.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e812f6c-7858-4207-86da-9d02bbf5ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toimg(img_url):\n",
    "    request.urlretrieve(img_url, 'img')\n",
    "    img = Image.open('img')\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "def imgtoarray(img_url):\n",
    "    try:\n",
    "        img = toimg(img_url)\n",
    "        return np.asarray(img, dtype=np.float32)\n",
    "    except TypeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6339e88-2623-4f0f-8c47-7d660dfdeed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cp1/lib/python3.8/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7264, 7264)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "for service in ['Apple', 'Google', 'Facebook', 'Windows']:\n",
    "    for url in df[service].values:\n",
    "        images.append(imgtoarray(url))\n",
    "labels = df['name'].to_list()*4\n",
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ab9760-87af-4496-a01f-90a03453e3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>grinning face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>grinning face with big eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>beaming face with smiling eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>grinning squinting face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>crossed flags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>black flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>white flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>rainbow flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812</th>\n",
       "      <td>[[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...</td>\n",
       "      <td>pirate flag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6813 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Image  \\\n",
       "0     [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "1     [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "2     [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "3     [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "4     [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "...                                                 ...   \n",
       "6808  [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "6809  [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "6810  [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "6811  [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "6812  [[[71.0, 112.0, 76.0], [71.0, 112.0, 76.0], [7...   \n",
       "\n",
       "                                Label  \n",
       "0                       grinning face  \n",
       "1         grinning face with big eyes  \n",
       "2     grinning face with smiling eyes  \n",
       "3      beaming face with smiling eyes  \n",
       "4             grinning squinting face  \n",
       "...                               ...  \n",
       "6808                    crossed flags  \n",
       "6809                       black flag  \n",
       "6810                       white flag  \n",
       "6811                     rainbow flag  \n",
       "6812                      pirate flag  \n",
       "\n",
       "[6813 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame(zip(images, labels), columns=['Image', 'Label'])\n",
    "df_new.dropna(axis=0, inplace=True)\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f930efd-9d84-4529-99df-a941cc94e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df_new['Label'] = df_new['Label'].apply(lambda x: ''.join(re.findall(r'[ A-Za-z0-9]', x))).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea37edd2-38eb-48b7-afbf-75efdf01c35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df_new['Label'].values\n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_dic = tokenizer.word_index\n",
    "vocab_size = len(word_dic)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9512ef8c-f53c-4326-8c10-67b191b127e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6813, 72, 72, 3), (6813, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded = pad_sequences(sequences)\n",
    "Images = np.stack(df_new['Image'].values)\n",
    "Labels = np.asarray(padded, dtype=np.float32)\n",
    "\n",
    "Images.shape, Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7b02b2-5a1b-4a45-b5d4-b4b7bbcf56f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5450, 72, 72, 3), (1363, 72, 72, 3), (5450, 6), (1363, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_images(images):\n",
    "    images = images.reshape((images.shape[0], 72, 72, 3)) / 255.\n",
    "    # return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
    "    return images.astype('float32')\n",
    "    \n",
    "\n",
    "ths_hold = int(Images.shape[0]*0.8)\n",
    "train_images = Images[:ths_hold, :,:,:]\n",
    "test_images = Images[ths_hold:, :,:,:]\n",
    "train_labels = Labels[:ths_hold, :]\n",
    "test_labels = Labels[ths_hold:, :]\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)\n",
    "train_images.shape, test_images.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a06749-94ca-4b7c-834a-14cfc641ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a037e9a-b0aa-4f36-ab6b-980057b975de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 16:49:24.181698: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-16 16:49:24.181837: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 72, 72, 3), (None, 6)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ee77e7-3926-4616-a6bf-dcbb55b2c19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 72, 72, 3), (None, 6)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=512).batch(batch_size)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecd83aed-b25b-40ff-b262-8f19051c7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e29dad2-7637-494e-86f5-f5e67cda548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim, len_text):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.emb_dim = 100\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(72, 72, 3)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=128, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim+self.emb_dim,)),\n",
    "                tf.keras.layers.Dense(units=18*18*32, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape(target_shape=(18, 18, 32)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=128, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                # No activation\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=3, kernel_size=3, strides=1, padding='same'),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.word_embbeding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(len_text,)),\n",
    "                tf.keras.layers.Embedding(vocab_size, 300, input_length=len_text),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(self.emb_dim),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    @tf.function\n",
    "    def predict(self, y_texts):\n",
    "        word_vec = self.word_embbeding(y_texts)\n",
    "        eps = tf.random.normal(shape=(len(y_texts), self.latent_dim))\n",
    "        z = tf.concat([eps, word_vec], axis=1)\n",
    "        return self.decode(z, apply_sigmoid=True)\n",
    "    \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim+self.len_text))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    @tf.function\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db0ed30-d00e-4572-a303-e05766e580c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x, x_text):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_text = tf.cast(x_text, dtype='float32')\n",
    "    x_text = tf.reshape(x_text, [-1,6])\n",
    "    word_vec = model.word_embbeding(x_text)\n",
    "    z_ = tf.concat([z, word_vec], axis=1)\n",
    "    x_logit = model.decode(z_)\n",
    "    x_logit = tf.cast(x_logit, dtype='float64')\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpx_z = tf.cast(logpx_z, dtype='float32')\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, x_text, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x, x_text)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eade7932-2553-483a-9d77-2f9272006f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 4\n",
    "num_examples_to_generate = 10\n",
    "len_text = 6\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim, len_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd0af722-df43-499a-b0fc-3186611972d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save_images(model, epoch, y_text):\n",
    "    test_seq = tokenizer.texts_to_sequences(y_text)\n",
    "    test_pad = pad_sequences(test_seq, maxlen=6)\n",
    "    test_pad = tf.cast(test_pad, dtype='float32')\n",
    "    predictions = model.predict(test_pad)\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(np.asarray(predictions[i, :, :, :]*255, dtype=np.int32))\n",
    "        plt.xlabel(y_text[i])\n",
    "\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig('./vae_imgs/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d79fa17f-f050-487a-8424-46645c782d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['smiling face with angry eyes', 'cold face', 'grinning face', 'winking face with tongue', \n",
    "        'fearful face with spiral eyes', 'sleepy face', 'screaming face with tongue', 'angry face', \n",
    "        'grinning face in clouds', 'hot zipper mouth face', 'vommiting poo', 'nerd face', \n",
    "       'beaming face with hearts', 'shushing poo', 'sad face with cowboy hat', 'flushed face with sunglasses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfa29b-bcb5-4268-8170-2bc500e5d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 880, Test set ELBO: -11907.30078125, time elapse for current epoch: 4.386445760726929\n"
     ]
    }
   ],
   "source": [
    "predict_and_save_images(model, 0, test)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for img, label in train_dataset:\n",
    "        img = tf.cast(img, dtype='float64')\n",
    "        train_step(model, img, label, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for img, label in test_dataset:\n",
    "        img = tf.cast(img, dtype='float64')\n",
    "        loss(compute_loss(model, img, label))\n",
    "    elbo = -loss.result()\n",
    "    display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n",
    "    predict_and_save_images(model, epoch, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf238eee-da8a-4f0f-b9cf-30135727a371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
